{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"Data/fake reviews dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the category names\n",
    "old_cat = ['Home_and_Kitchen_5', 'Sports_and_Outdoors_5', 'Electronics_5',\n",
    "       'Movies_and_TV_5', 'Tools_and_Home_Improvement_5',\n",
    "       'Pet_Supplies_5', 'Kindle_Store_5', 'Books_5', 'Toys_and_Games_5',\n",
    "       'Clothing_Shoes_and_Jewelry_5']\n",
    "new_cat = ['Home and Kitchen', 'Sports and Outdoors', 'Electronics',\n",
    "        'Movies and TV', 'Tools and Home Improvement',\n",
    "        'Pet Supplies', 'Kindle Store', 'Books', 'Toys and Games',\n",
    "        'Clothing Shoes and Jewelry']\n",
    "df['category'].replace(to_replace=old_cat, value=new_cat, inplace=True)\n",
    "\n",
    "# Remove any duplicate rows, then check for NA values for each column\n",
    "df = df.drop_duplicates(subset='text_')\n",
    "df['text_'].replace(\".   .                   \", np.nan, inplace=True)\n",
    "df.dropna(subset=['text_'], inplace=True)\n",
    "\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Rename columns so that they are more descriptive\n",
    "colnames_dict = {\"label\": \"type\", \"text_\": \"comments\"}\n",
    "df.rename(columns=colnames_dict, inplace=True)\n",
    "\n",
    "# Map the type column to numeric/boolean values:\n",
    "  # OR (Original reviews, presumably human-created and authentic) = 0\n",
    "  # CG (Computer-generated fake reviews) = 1\n",
    "\n",
    "type_dict_map = {'OR': 0 ,'CG':1}\n",
    "df['type'] = df['type'].map(type_dict_map)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the review counts for each types\n",
    "type_counts = df['type'].value_counts()\n",
    "print(\"Number of type 0 reviews:\", type_counts[0])\n",
    "print(\"Number of type 1 reviews:\", type_counts[1])\n",
    "\n",
    "#Numbers of review in each type\n",
    "sns.countplot(data=df,x='type')\n",
    "plt.title('Number of Type 0 and Type 1 Reviews')\n",
    "plt.xlabel('Review Type')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks([0, 1], ['Original Reviews', 'Computer-Generated Reviews'])\n",
    "plt.show()\n",
    "\n",
    "# Numbers of comment in each category\n",
    "category_counts = df['category'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "barplot = sns.barplot(x=category_counts.index, y=category_counts.values)\n",
    "plt.title('Number of Comments in Each Category')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Number of Comments')\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability\n",
    "plt.tight_layout()\n",
    "for bar in barplot.patches:\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), int(bar.get_height()),\n",
    "             ha='center', va='bottom')\n",
    "plt.show()\n",
    "\n",
    "#Proportions of different categories\n",
    "plt.figure(figsize=(8, 8))\n",
    "category_counts.plot(kind='pie', autopct='%1.1f%%', startangle=140)\n",
    "plt.title('Proportions of different categories')\n",
    "plt.ylabel('')\n",
    "plt.show()\n",
    "\n",
    "#Types of review in each category\n",
    "plt.figure(figsize=(14, 8))\n",
    "bars =sns.countplot(data=df, x='category', hue='type', palette='Set2')\n",
    "plt.title('Number of Original and Computer-Generated Reviews by Category')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)  \n",
    "plt.legend(title='Review Type', labels=['Original Reviews', 'Computer-Generated Reviews'])\n",
    "for bar in bars.patches:\n",
    "    bars.annotate(f'{int(bar.get_height())}',\n",
    "                  (bar.get_x() + bar.get_width() / 2, bar.get_height()),\n",
    "                  ha='center', va='bottom')\n",
    "plt.show()\n",
    "\n",
    "#Rating distribution\n",
    "hist=sns.histplot(data=df, x='rating', bins=5,)\n",
    "plt.title('Distribution of Ratings')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(range(1, 6))\n",
    "for p in hist.patches:\n",
    "    hist.annotate(f'{int(p.get_height())}', \n",
    "                  (p.get_x() + p.get_width() / 2, p.get_height()), \n",
    "                  ha='center', va='bottom')\n",
    "plt.show()\n",
    "\n",
    "# the number of different types reviews by rating\n",
    "review_counts = df.groupby(['rating', 'type']).size()\n",
    "print(review_counts)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='type', y='rating', data=df)\n",
    "plt.title('Relationship Between Rating and Review Type')\n",
    "plt.xlabel('Review Type')\n",
    "plt.ylabel('Rating')\n",
    "plt.xticks([0, 1], ['Original Reviews', 'Computer-Generated Reviews'])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target_var  = 'type'\n",
    "feature_var = [ 'rating', 'comments']\n",
    "X = df[feature_var]\n",
    "y = df[target_var]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True, random_state=101)\n",
    "y_train = y_train.values.reshape(-1, 1)\n",
    "y_test = y_test.values.reshape(-1, 1)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(X_train.head())\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(X_test.head())\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(y_train[:5])\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "print(y_test[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Create a pipeline to vectorize the text data and then apply the logistic regression model\n",
    "pipeline_log = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features=20000)),\n",
    "    ('logistic', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Transform comment to tfidf\n",
    "X_train_tfidf = pipeline_log.named_steps['tfidf'].fit_transform(X_train['comments'])\n",
    "X_test_tfidf = pipeline_log.named_steps['tfidf'].fit_transform(X_test['comments'])\n",
    "\n",
    "print(X_train_tfidf[0])\n",
    "print(X_test_tfidf[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression with 'comments' column\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Create a pipeline to vectorize the text data and then apply the logistic regression model\n",
    "pipeline_log = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features=20000)),\n",
    "    ('logistic', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Perform cross-validation and print the scores\n",
    "cv_scores_log = cross_val_score(pipeline_log, X_train['comments'], y_train.ravel(), cv=5)  # Choose appropriate cv value\n",
    "print(\"Cross-Validation Scores:\", cv_scores_log)\n",
    "\n",
    "# Fit pipeline to training data and make predictions\n",
    "pipeline_log.fit(X_train['comments'], y_train.ravel())\n",
    "predictions_log = pipeline_log.predict(X_test['comments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print model evaluation metrics\n",
    "# Calculate accuracy\n",
    "acc_log = metrics.accuracy_score(predictions_log, y_test.ravel())\n",
    "print('Accuracy of logistic regression model:', acc_log)\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "print(metrics.classification_report(y_test, predictions_log))\n",
    "print(metrics.confusion_matrix(y_test, predictions_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression with 'comments' and 'rating' columns\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Create a pipeline for TF-IDF vectorization of the 'comments' column\n",
    "tfidf_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features=20000))\n",
    "])\n",
    "\n",
    "# Create a ColumnTransformer to apply different transformations to different columns\n",
    "preprocessor_log = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('comments_tfidf', tfidf_pipeline, 'comments'),  # Apply TF-IDF to 'comments' column\n",
    "        ('passthrough', 'passthrough', ['rating'])  # Pass through 'type' column as it is\n",
    "    ],\n",
    "    remainder='drop'  # Drop any columns not specified in the transformers\n",
    ")\n",
    "\n",
    "# Create the final pipeline by combining preprocessor and logistic regression\n",
    "pipeline_log2 = Pipeline([\n",
    "    ('preprocessor', preprocessor_log),\n",
    "    ('logistic', LogisticRegression(solver='sag'))\n",
    "])\n",
    "\n",
    "# Perform cross-validation and print the scores\n",
    "cv_scores_log2 = cross_val_score(pipeline_log2, X_train, y_train.ravel(), cv=5)\n",
    "print(\"Cross-Validation Scores:\", cv_scores_log2)\n",
    "\n",
    "# Fit pipeline to training data and make predictions\n",
    "pipeline_log2.fit(X_train, y_train.ravel())\n",
    "predictions_log2 = pipeline_log2.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print model evaluation metrics\n",
    "# Calculate accuracy\n",
    "acc_log2 = metrics.accuracy_score(predictions_log2, y_test.ravel())\n",
    "print('Accuracy of logistic regression model:', acc_log2)\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "print(metrics.classification_report(y_test, predictions_log2))\n",
    "print(metrics.confusion_matrix(y_test, predictions_log2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multinomial Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Create a pipeline to vectorize the text data and then apply the logistic regression model\n",
    "pipeline_multiNB = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features=20000)),\n",
    "    ('Multinomial NB', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Perform cross-validation and print the scores\n",
    "cv_score_multiNB = cross_val_score(pipeline_multiNB, X_train['comments'], y_train.ravel(), cv=5)  # Choose appropriate cv value\n",
    "print(\"Cross-Validation Scores:\", cv_score_multiNB)\n",
    "\n",
    "# Fit pipeline to training data and make predictions\n",
    "pipeline_multiNB.fit(X_train['comments'], y_train.ravel())\n",
    "predictions_multiNB = pipeline_multiNB.predict(X_test['comments'])\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "print(classification_report(y_test, predictions_multiNB))\n",
    "print(confusion_matrix(y_test, predictions_multiNB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multinomial NB with 'comments' and 'rating' columns\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Create a ColumnTransformer to apply different transformations to different columns\n",
    "preprocessor_log = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('comments_tfidf', tfidf_pipeline, 'comments'),  # Apply TF-IDF to 'comments' column\n",
    "        ('passthrough', 'passthrough', ['rating'])  # Pass through 'type' column as it is\n",
    "    ],\n",
    "    remainder='drop'  # Drop any columns not specified in the transformers\n",
    ")\n",
    "\n",
    "# Create the final pipeline by combining preprocessor and logistic regression\n",
    "pipeline_multiNB2 = Pipeline([\n",
    "    ('preprocessor', preprocessor_log),\n",
    "    ('Multinomial NB', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Perform cross-validation and print the scores\n",
    "cv_scores_multiNB2 = cross_val_score(pipeline_multiNB2, X_train, y_train.ravel(), cv=5)\n",
    "print(\"Cross-Validation Scores:\", cv_scores_multiNB2)\n",
    "\n",
    "# Fit pipeline to training data and make predictions\n",
    "pipeline_multiNB2.fit(X_train, y_train.ravel())\n",
    "predictions_multiNB2 = pipeline_multiNB2.predict(X_test)\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "print(classification_report(y_test, predictions_multiNB))\n",
    "print(confusion_matrix(y_test, predictions_multiNB))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Ask for user input\n",
    "rating = int(input(\"Enter the rating (1-5): \"))\n",
    "comment = input(\"Enter the comment: \")\n",
    "\n",
    "# Create a DataFrame with the user input\n",
    "user_data = pd.DataFrame({'rating': [rating],\n",
    "                          'comments': [comment]})\n",
    "\n",
    "# Transform the user input using the TF-IDF vectorizer\n",
    "user_data_tfidf = pipeline.named_steps['tfidf'].transform(user_data['comments'])\n",
    "\n",
    "# Predict the output using the trained classifier\n",
    "prediction = pipeline.named_steps['classifier'].predict(user_data_tfidf.toarray())\n",
    "\n",
    "# Calculate accuracy if actual output is available\n",
    "# OR (Original reviews, presumably human-created and authentic) = 0\n",
    "# CG (Computer-generated fake reviews) = 1\n",
    "actual_output = 0  \n",
    "accuracy = accuracy_score([actual_output], prediction)\n",
    "# Print the prediction and accuracy\n",
    "if prediction[0] == 0:\n",
    "    print(\"Original review (OR)\")\n",
    "else:\n",
    "    print(\"Computer-generated fake review (CG)\")\n",
    "\n",
    "print(\"Prediction Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "Below are backup code that didn't really work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline_nb = Pipeline([\n",
    "    # Remove the max_features limitation at the end.\n",
    "    ('tfidf', TfidfVectorizer(max_features=20000)),  # TF-IDF vectorizer\n",
    "    ('classifier', GaussianNB())    # Gaussian Naive Bayes classifier\n",
    "])\n",
    "\n",
    "# Transform comment to tfidf\n",
    "X_train_tfidf = pipeline_nb.named_steps['tfidf'].fit_transform(X_train['comments'])\n",
    "X_test_tfidf = pipeline_nb.named_steps['tfidf'].fit_transform(X_test['comments'])\n",
    "\n",
    "X_train_tfidf = X_train_tfidf.toarray()\n",
    "X_test_tfidf = X_test_tfidf.toarray()\n",
    "\n",
    "# Cross validation\n",
    "kfold = KFold(n_splits=5, shuffle=False, random_state=None)\n",
    "rkfold = RepeatedKFold(n_splits=5, n_repeats=10, random_state=None)\n",
    "\n",
    "params = {'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2]}\n",
    "model = GaussianNB()\n",
    "\n",
    "grid_nb = GridSearchCV(estimator=model, param_grid=params, scoring='accuracy', cv=5, verbose=1)\n",
    "\n",
    "# Fit the function to train set \n",
    "grid_nb.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Find the best parameter and see how well it performs on test set\n",
    "print(grid_nb.best_params_)\n",
    "print(grid_nb.score(X_test_tfidf, y_test))\n",
    "print(grid_nb.cv_results_['mean_test_score'])\n",
    "\n",
    "\n",
    "# Below are code for validation\n",
    "# print('kFold accuracy scores are', cross_val_score(pipeline_nb.named_steps['classifier'], X_train_tfidf, y_train, scoring='precision', cv= kfold, n_jobs=-1))\n",
    "# print('repeated kFold accuracy scores are', cross_val_score(pipeline_nb.named_steps['classifier'], X_train_tfidf, y_train, scoring='precision', cv= rkfold, n_jobs=-1))\n",
    "\n",
    "# print('The average KFold scores is', np.mean(cross_val_score(pipeline.named_steps['classifier'], X_train_tfidf, y_train, scoring='accuracy', cv=kfold, n_jobs=-1)))\n",
    "# print('The average RepeatedKFold score is', np.mean(cross_val_score(pipeline.named_steps['classifier'], X_train_tfidf, y_train, cv=rkfold, n_jobs=-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline_nb = Pipeline([\n",
    "    # Remove the max_features limitation at the end.\n",
    "    ('tfidf', TfidfVectorizer(max_features=20000)),  # TF-IDF vectorizer\n",
    "    ('classifier', GaussianNB(var_smoothing=0.002))    # Gaussian Naive Bayes classifier\n",
    "])\n",
    "# Transform comment to tfidf\n",
    "X_train_tfidf = pipeline_nb.named_steps['tfidf'].fit_transform(X_train['comments'])\n",
    "X_test_tfidf = pipeline_nb.named_steps['tfidf'].fit_transform(X_test['comments'])\n",
    "\n",
    "X_train_tfidf = X_train_tfidf.toarray()\n",
    "X_test_tfidf = X_test_tfidf.toarray()\n",
    "\n",
    "model_nb = pipeline_nb.named_steps['classifier'].fit(X_train_tfidf, y_train.ravel())\n",
    "\n",
    "# Evaluate the model\n",
    "train_accuracy = pipeline_nb.named_steps['classifier'].score(X_train_tfidf, y_train)\n",
    "test_accuracy = pipeline_nb.named_steps['classifier'].score(X_test_tfidf, y_test)\n",
    "\n",
    "feature_names =  pipeline_nb.named_steps['tfidf'].get_feature_names_out()\n",
    "num_features = len(feature_names)\n",
    "\n",
    "print(\"Number of features (vocabulary size):\", num_features)\n",
    "print(\"This accuracy score shows\")\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Testing Accuracy:\", test_accuracy)\n",
    "\n",
    "predict_nb = model_nb.predict(X_test_tfidf)\n",
    "\n",
    "acc = accuracy_score(predict_nb, y_test)\n",
    "precision = precision_score(predict_nb, y_test)\n",
    "recall = recall_score(predict_nb, y_test)\n",
    "f1 = f1_score(predict_nb, y_test)\n",
    "\n",
    "print('The accuracy score of NB is', acc)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform each comment row into tfidf array\n",
    "df['comments'] = df['comments'].astype(str)\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "# print(df['comments'])\n",
    "for index, row in df.iterrows():\n",
    "    # Transform the comment into a TF-IDF array\n",
    "    comment = row['comments']\n",
    "    # Check if the comment is empty or contains only stop words\n",
    "    \n",
    "\n",
    "    # Transform the comment into a TF-IDF array\n",
    "    comment_tfidf = vectorizer.fit_transform([comment]).toarray()\n",
    "    # Replace the original comment with its TF-IDF array\n",
    "    df.at[index, 'comments'] = comment_tfidf\n",
    "\n",
    "# response = vectorizer.fit_transform(df['comments'])\n",
    "# df['comments'] = response.getnnz()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Initialize the Naive Bayes classifier\n",
    "model = GaussianNB()\n",
    "print(\"error1\")\n",
    "# Train the classifier\n",
    "model.fit(X_train, y_train)\n",
    "print(\"error2\")\n",
    "\n",
    "# Predictions on the training set\n",
    "train_preds = model.predict(X_train)\n",
    "print(\"error3\")\n",
    "\n",
    "# Predictions on the testing set\n",
    "test_preds = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "train_accuracy = accuracy_score(y_train, train_preds)\n",
    "test_accuracy = accuracy_score(y_test, test_preds)\n",
    "\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Testing Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
