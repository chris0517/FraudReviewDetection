{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "df = pd.read_csv(\"Data/fake reviews dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category    0\n",
      "rating      0\n",
      "label       0\n",
      "text_       0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>type</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Home and Kitchen</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Love this!  Well made, sturdy, and very comfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Home and Kitchen</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>love it, a great upgrade from the original.  I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Home and Kitchen</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>This pillow saved my back. I love the look and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Home and Kitchen</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Missing information on how to use it, but it i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Home and Kitchen</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Very nice set. Good quality. We have had the s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           category  rating  type  \\\n",
       "0  Home and Kitchen     5.0     1   \n",
       "1  Home and Kitchen     5.0     1   \n",
       "2  Home and Kitchen     5.0     1   \n",
       "3  Home and Kitchen     1.0     1   \n",
       "4  Home and Kitchen     5.0     1   \n",
       "\n",
       "                                            comments  \n",
       "0  Love this!  Well made, sturdy, and very comfor...  \n",
       "1  love it, a great upgrade from the original.  I...  \n",
       "2  This pillow saved my back. I love the look and...  \n",
       "3  Missing information on how to use it, but it i...  \n",
       "4  Very nice set. Good quality. We have had the s...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean up the category names\n",
    "old_cat = ['Home_and_Kitchen_5', 'Sports_and_Outdoors_5', 'Electronics_5',\n",
    "       'Movies_and_TV_5', 'Tools_and_Home_Improvement_5',\n",
    "       'Pet_Supplies_5', 'Kindle_Store_5', 'Books_5', 'Toys_and_Games_5',\n",
    "       'Clothing_Shoes_and_Jewelry_5']\n",
    "new_cat = ['Home and Kitchen', 'Sports and Outdoors', 'Electronics',\n",
    "        'Movies and TV', 'Tools and Home Improvement',\n",
    "        'Pet Supplies', 'Kindle Store', 'Books', 'Toys and Games',\n",
    "        'Clothing Shoes and Jewelry']\n",
    "df['category'].replace(to_replace=old_cat, value=new_cat, inplace=True)\n",
    "\n",
    "# Remove any duplicate rows, then check for NA values for each column\n",
    "df = df.drop_duplicates(subset='text_')\n",
    "df['text_'].replace(\".   .                   \", np.nan, inplace=True)\n",
    "df.dropna(subset=['text_'], inplace=True)\n",
    "\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Rename columns so that they are more descriptive\n",
    "colnames_dict = {\"label\": \"type\", \"text_\": \"comments\"}\n",
    "df.rename(columns=colnames_dict, inplace=True)\n",
    "\n",
    "# Map the type column to numeric/boolean values:\n",
    "  # OR (Original reviews, presumably human-created and authentic) = 0\n",
    "  # CG (Computer-generated fake reviews) = 1\n",
    "\n",
    "type_dict_map = {'OR': 0 ,'CG':1}\n",
    "df['type'] = df['type'].map(type_dict_map)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (28287, 2)\n",
      "       rating                                           comments\n",
      "7569      5.0  Great Cooler. Cheaper than other high end cool...\n",
      "30086     4.0  Wow i can't believe Richards left me hanging n...\n",
      "28669     2.0  Just didn't hold my interest. I finished it, b...\n",
      "28491     4.0  it's a tough subject, this book has the potent...\n",
      "3986      4.0  This is a decent storage rack. The only proble...\n",
      "X_test shape: (12124, 2)\n",
      "       rating                                           comments\n",
      "27462     2.0  'Name that Doggy!' Because it was an easy read...\n",
      "4476      5.0  These are good targets to add a bit of realism...\n",
      "38652     5.0  I love this watch!  It has the wide band which...\n",
      "11314     3.0  It does as advertised, mostly. It's on the bug...\n",
      "21592     5.0  I have 2 boxers that I felt needed a little wa...\n",
      "y_train shape: (28287, 1)\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]]\n",
      "y_test shape: (12124, 1)\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "target_var  = 'type'\n",
    "feature_var = [ 'rating', 'comments']\n",
    "X = df[feature_var]\n",
    "y = df[target_var]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True, random_state=101)\n",
    "y_train = y_train.values.reshape(-1, 1)\n",
    "y_test = y_test.values.reshape(-1, 1)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(X_train.head())\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(X_test.head())\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(y_train[:5])\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "print(y_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 18892)\t0.07557085908011478\n",
      "  (0, 8448)\t0.07429557043831958\n",
      "  (0, 10118)\t0.060008654438684715\n",
      "  (0, 18161)\t0.04731021720574824\n",
      "  (0, 6107)\t0.0814416734565174\n",
      "  (0, 1246)\t0.07435528176479633\n",
      "  (0, 10520)\t0.10955999856061753\n",
      "  (0, 7465)\t0.09871763912247238\n",
      "  (0, 19512)\t0.048734521557744916\n",
      "  (0, 3088)\t0.08041327408864679\n",
      "  (0, 5945)\t0.07260836411962672\n",
      "  (0, 19584)\t0.07736553529731821\n",
      "  (0, 6251)\t0.05900520552150097\n",
      "  (0, 10382)\t0.05957489879646748\n",
      "  (0, 9767)\t0.03990911378434627\n",
      "  (0, 1043)\t0.0457694410354829\n",
      "  (0, 15564)\t0.09274967045411944\n",
      "  (0, 1694)\t0.05922830272487444\n",
      "  (0, 9824)\t0.05536249329485334\n",
      "  (0, 5943)\t0.08208495123545609\n",
      "  (0, 18263)\t0.14941930686932034\n",
      "  (0, 11745)\t0.05841380157258264\n",
      "  (0, 12242)\t0.025317707409692938\n",
      "  (0, 18468)\t0.11412511367764698\n",
      "  (0, 9039)\t0.05735535990164553\n",
      "  :\t:\n",
      "  (0, 17967)\t0.1931828085130935\n",
      "  (0, 19472)\t0.07889929009013393\n",
      "  (0, 1143)\t0.09554695741631528\n",
      "  (0, 10136)\t0.13324902837598637\n",
      "  (0, 12341)\t0.1074319332195513\n",
      "  (0, 18100)\t0.15585015007571357\n",
      "  (0, 5952)\t0.09829922691074444\n",
      "  (0, 19906)\t0.07076298477676465\n",
      "  (0, 15586)\t0.09098128773902037\n",
      "  (0, 4131)\t0.09254235967784002\n",
      "  (0, 14964)\t0.1267457708341561\n",
      "  (0, 6628)\t0.1451849657126922\n",
      "  (0, 6819)\t0.08957002102839946\n",
      "  (0, 2111)\t0.05818500327146238\n",
      "  (0, 4103)\t0.09919504816599621\n",
      "  (0, 19501)\t0.04828493860035166\n",
      "  (0, 19673)\t0.12187806380919063\n",
      "  (0, 4251)\t0.1349826558877112\n",
      "  (0, 6193)\t0.06680067458632051\n",
      "  (0, 8544)\t0.07250247285866052\n",
      "  (0, 12441)\t0.048269678026884956\n",
      "  (0, 17831)\t0.04853128446437073\n",
      "  (0, 3328)\t0.08859382986644772\n",
      "  (0, 4250)\t0.22115098468164426\n",
      "  (0, 7995)\t0.03314033640010858\n",
      "  (0, 5797)\t0.08477476797621501\n",
      "  (0, 13945)\t0.07700503339761011\n",
      "  (0, 12387)\t0.04557181052079394\n",
      "  (0, 4352)\t0.08122813402923314\n",
      "  (0, 13290)\t0.09039083480942946\n",
      "  (0, 7323)\t0.1354045722207489\n",
      "  (0, 14105)\t0.09776360706299932\n",
      "  (0, 19371)\t0.07130770381443917\n",
      "  (0, 6615)\t0.10993436318016613\n",
      "  (0, 15917)\t0.05219177589351842\n",
      "  (0, 837)\t0.10144498236068367\n",
      "  (0, 15604)\t0.12430329010012595\n",
      "  (0, 12625)\t0.05078236308572994\n",
      "  (0, 19272)\t0.0746409854992534\n",
      "  (0, 12005)\t0.040781229071787786\n",
      "  (0, 12621)\t0.04898286988586563\n",
      "  (0, 9390)\t0.08116853632774394\n",
      "  (0, 12236)\t0.16778501607418042\n",
      "  (0, 19114)\t0.09352082586190762\n",
      "  (0, 3374)\t0.05947009066115521\n",
      "  (0, 18897)\t0.04589161820188128\n",
      "  (0, 9085)\t0.1307788109518305\n",
      "  (0, 1983)\t0.08389250803709021\n",
      "  (0, 7638)\t0.127445053059594\n",
      "  (0, 11807)\t0.062151321785078546\n",
      "  :\t:\n",
      "  (0, 2908)\t0.3032195337439213\n",
      "  (0, 17598)\t0.1598091104559336\n",
      "  (0, 14100)\t0.25114001049001755\n",
      "  (0, 6437)\t0.08132329860161003\n",
      "  (0, 15144)\t0.15722979205458412\n",
      "  (0, 2469)\t0.22384557070186398\n",
      "  (0, 7419)\t0.03572900339801781\n",
      "  (0, 11984)\t0.09797549967048809\n",
      "  (0, 8778)\t0.11234442659044792\n",
      "  (0, 12549)\t0.07122601320143156\n",
      "  (0, 10833)\t0.07164381957396385\n",
      "  (0, 8669)\t0.058453923685494076\n",
      "  (0, 16622)\t0.19157699475357437\n",
      "  (0, 17517)\t0.2507554438441853\n",
      "  (0, 10856)\t0.3188127340462825\n",
      "  (0, 1470)\t0.13456525322259177\n",
      "  (0, 14096)\t0.3192949912559573\n",
      "  (0, 6119)\t0.06885081564811671\n",
      "  (0, 1449)\t0.0609391264862668\n",
      "  (0, 19212)\t0.13635942985002444\n",
      "  (0, 9706)\t0.18155098577760037\n",
      "  (0, 2423)\t0.07296045117956977\n",
      "  (0, 5697)\t0.17851135298062837\n",
      "  (0, 17513)\t0.04203263589442029\n",
      "  (0, 12044)\t0.12214446464920596\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Create a pipeline to vectorize the text data and then apply the logistic regression model\n",
    "pipeline_log = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features=20000)),\n",
    "    ('logistic', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Transform comment to tfidf\n",
    "X_train_tfidf = pipeline_log.named_steps['tfidf'].fit_transform(X_train['comments'])\n",
    "X_test_tfidf = pipeline_log.named_steps['tfidf'].fit_transform(X_test['comments'])\n",
    "\n",
    "print(X_train_tfidf[0])\n",
    "print(X_test_tfidf[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores: [0.90261577 0.90509014 0.89711861 0.8934064  0.89676507]\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression with 'comments' column\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Create a pipeline to vectorize the text data and then apply the logistic regression model\n",
    "pipeline_log = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features=20000)),\n",
    "    ('logistic', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Perform cross-validation and print the scores\n",
    "cv_scores_log = cross_val_score(pipeline_log, X_train['comments'], y_train.ravel(), cv=5)  # Choose appropriate cv value\n",
    "print(\"Cross-Validation Scores:\", cv_scores_log)\n",
    "\n",
    "# Fit pipeline to training data and make predictions\n",
    "pipeline_log.fit(X_train['comments'], y_train.ravel())\n",
    "predictions_log = pipeline_log.predict(X_test['comments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of logistic regression model is 0.8992081821181128\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.90      6042\n",
      "           1       0.91      0.88      0.90      6082\n",
      "\n",
      "    accuracy                           0.90     12124\n",
      "   macro avg       0.90      0.90      0.90     12124\n",
      "weighted avg       0.90      0.90      0.90     12124\n",
      "\n",
      "[[5530  512]\n",
      " [ 710 5372]]\n"
     ]
    }
   ],
   "source": [
    "## Print model evaluation metrics\n",
    "# Calculate accuracy\n",
    "acc_log = metrics.accuracy_score(predictions_log, y_test.ravel())\n",
    "print('Accuracy of logistic regression model:', acc_log)\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "print(metrics.classification_report(y_test, predictions_log))\n",
    "print(metrics.confusion_matrix(y_test, predictions_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores: [0.90296925 0.90544362 0.89623475 0.89429026 0.89552766]\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression with 'comments' and 'rating' columns\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Create a pipeline for TF-IDF vectorization of the 'comments' column\n",
    "tfidf_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features=20000))\n",
    "])\n",
    "\n",
    "# Create a ColumnTransformer to apply different transformations to different columns\n",
    "preprocessor_log = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('comments_tfidf', tfidf_pipeline, 'comments'),  # Apply TF-IDF to 'comments' column\n",
    "        ('passthrough', 'passthrough', ['rating'])  # Pass through 'type' column as it is\n",
    "    ],\n",
    "    remainder='drop'  # Drop any columns not specified in the transformers\n",
    ")\n",
    "\n",
    "# Create the final pipeline by combining preprocessor and logistic regression\n",
    "pipeline_log2 = Pipeline([\n",
    "    ('preprocessor', preprocessor_log),\n",
    "    ('logistic', LogisticRegression(solver='sag'))\n",
    "])\n",
    "\n",
    "# Perform cross-validation and print the scores\n",
    "cv_scores_log2 = cross_val_score(pipeline_log2, X_train, y_train.ravel(), cv=5)\n",
    "print(\"Cross-Validation Scores:\", cv_scores_log2)\n",
    "\n",
    "# Fit pipeline to training data and make predictions\n",
    "pipeline_log2.fit(X_train, y_train.ravel())\n",
    "predictions_log2 = pipeline_log2.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression model: 0.8992081821181128\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.90      6042\n",
      "           1       0.91      0.88      0.90      6082\n",
      "\n",
      "    accuracy                           0.90     12124\n",
      "   macro avg       0.90      0.90      0.90     12124\n",
      "weighted avg       0.90      0.90      0.90     12124\n",
      "\n",
      "[[5530  512]\n",
      " [ 710 5372]]\n"
     ]
    }
   ],
   "source": [
    "## Print model evaluation metrics\n",
    "# Calculate accuracy\n",
    "acc_log2 = metrics.accuracy_score(predictions_log2, y_test.ravel())\n",
    "print('Accuracy of logistic regression model:', acc_log2)\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "print(metrics.classification_report(y_test, predictions_log2))\n",
    "print(metrics.confusion_matrix(y_test, predictions_log2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores: [0.86002121 0.86532344 0.85928938 0.85610748 0.86070355]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.80      0.86      6042\n",
      "           1       0.83      0.93      0.88      6082\n",
      "\n",
      "    accuracy                           0.87     12124\n",
      "   macro avg       0.87      0.87      0.87     12124\n",
      "weighted avg       0.87      0.87      0.87     12124\n",
      "\n",
      "[[4861 1181]\n",
      " [ 425 5657]]\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Create a pipeline to vectorize the text data and then apply the logistic regression model\n",
    "pipeline_multiNB = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features=20000)),\n",
    "    ('Multinomial NB', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Perform cross-validation and print the scores\n",
    "cv_score_multiNB = cross_val_score(pipeline_multiNB, X_train['comments'], y_train.ravel(), cv=5)  # Choose appropriate cv value\n",
    "print(\"Cross-Validation Scores:\", cv_score_multiNB)\n",
    "\n",
    "# Fit pipeline to training data and make predictions\n",
    "pipeline_multiNB.fit(X_train['comments'], y_train.ravel())\n",
    "predictions_multiNB = pipeline_multiNB.predict(X_test['comments'])\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "print(classification_report(y_test, predictions_multiNB))\n",
    "print(confusion_matrix(y_test, predictions_multiNB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores: [0.84446801 0.85295157 0.84620824 0.84373343 0.85204172]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.80      0.86      6042\n",
      "           1       0.83      0.93      0.88      6082\n",
      "\n",
      "    accuracy                           0.87     12124\n",
      "   macro avg       0.87      0.87      0.87     12124\n",
      "weighted avg       0.87      0.87      0.87     12124\n",
      "\n",
      "[[4861 1181]\n",
      " [ 425 5657]]\n"
     ]
    }
   ],
   "source": [
    "# Multinomial NB with 'comments' and 'rating' columns\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Create a ColumnTransformer to apply different transformations to different columns\n",
    "preprocessor_log = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('comments_tfidf', tfidf_pipeline, 'comments'),  # Apply TF-IDF to 'comments' column\n",
    "        ('passthrough', 'passthrough', ['rating'])  # Pass through 'type' column as it is\n",
    "    ],\n",
    "    remainder='drop'  # Drop any columns not specified in the transformers\n",
    ")\n",
    "\n",
    "# Create the final pipeline by combining preprocessor and logistic regression\n",
    "pipeline_multiNB2 = Pipeline([\n",
    "    ('preprocessor', preprocessor_log),\n",
    "    ('Multinomial NB', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Perform cross-validation and print the scores\n",
    "cv_scores_multiNB2 = cross_val_score(pipeline_multiNB2, X_train, y_train.ravel(), cv=5)\n",
    "print(\"Cross-Validation Scores:\", cv_scores_multiNB2)\n",
    "\n",
    "# Fit pipeline to training data and make predictions\n",
    "pipeline_multiNB2.fit(X_train, y_train.ravel())\n",
    "predictions_multiNB2 = pipeline_multiNB2.predict(X_test)\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "print(classification_report(y_test, predictions_multiNB))\n",
    "print(confusion_matrix(y_test, predictions_multiNB))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chris\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Chris\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Chris\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Chris\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Chris\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Chris\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Chris\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Chris\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Chris\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Chris\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Chris\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Chris\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Chris\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Chris\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Chris\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Chris\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Chris\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Chris\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Chris\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Chris\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Chris\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Chris\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Chris\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Chris\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Chris\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Chris\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'var_smoothing': 1e-05}\n",
      "0.49843286044209834\n",
      "[0.74458255 0.74546634 0.74642075 0.74825907 0.75020343]\n",
      "Number of features (vocabulary size): 20000\n",
      "This accuracy score shows\n",
      "Training Accuracy: 0.8444868667585816\n",
      "Testing Accuracy: 0.49843286044209834\n",
      "The accuracy score of NB is 0.49843286044209834\n",
      "Precision: 0.0024662939822426835\n",
      "Recall: 0.5172413793103449\n",
      "F1 Score: 0.0049091801669121264\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline_nb = Pipeline([\n",
    "    # Remove the max_features limitation at the end.\n",
    "    ('tfidf', TfidfVectorizer(max_features=20000)),  # TF-IDF vectorizer\n",
    "    ('classifier', GaussianNB())    # Gaussian Naive Bayes classifier\n",
    "])\n",
    "\n",
    "# Transform comment to tfidf\n",
    "X_train_tfidf = pipeline_nb.named_steps['tfidf'].fit_transform(X_train['comments'])\n",
    "X_test_tfidf = pipeline_nb.named_steps['tfidf'].fit_transform(X_test['comments'])\n",
    "\n",
    "X_train_tfidf = X_train_tfidf.toarray()\n",
    "X_test_tfidf = X_test_tfidf.toarray()\n",
    "\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=False, random_state=None)\n",
    "rkfold = RepeatedKFold(n_splits=5, n_repeats=10, random_state=None)\n",
    "\n",
    "params = {'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5] }\n",
    "model = GaussianNB()\n",
    "\n",
    "grid_nb = GridSearchCV(estimator=model, param_grid=params, scoring='accuracy', cv=5, verbose=1)\n",
    "\n",
    "# Fit the function to train set \n",
    "grid_nb.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Find the best parameter and see how well it performs on test set\n",
    "print(grid_nb.best_params_)\n",
    "print(grid_nb.score(X_test_tfidf, y_test))\n",
    "print(grid_nb.cv_results_['mean_test_score'])\n",
    "\n",
    "model_nb = pipeline_nb.named_steps['classifier'].fit(X_train_tfidf, y_train.ravel())\n",
    "\n",
    "# Evaluate the model\n",
    "train_accuracy = pipeline_nb.named_steps['classifier'].score(X_train_tfidf, y_train)\n",
    "test_accuracy = pipeline_nb.named_steps['classifier'].score(X_test_tfidf, y_test)\n",
    "\n",
    "feature_names =  pipeline_nb.named_steps['tfidf'].get_feature_names_out()\n",
    "num_features = len(feature_names)\n",
    "\n",
    "print(\"Number of features (vocabulary size):\", num_features)\n",
    "print(\"This accuracy score shows\")\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Testing Accuracy:\", test_accuracy)\n",
    "\n",
    "predict_nb = model_nb.predict(X_test_tfidf)\n",
    "\n",
    "acc = accuracy_score(predict_nb, y_test)\n",
    "precision = precision_score(predict_nb, y_test)\n",
    "recall = recall_score(predict_nb, y_test)\n",
    "f1 = f1_score(predict_nb, y_test)\n",
    "\n",
    "print('The accuracy score of NB is', acc)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "\n",
    "# Below are code for validation\n",
    "# print('kFold accuracy scores are', cross_val_score(pipeline_nb.named_steps['classifier'], X_train_tfidf, y_train, scoring='precision', cv= kfold, n_jobs=-1))\n",
    "# print('repeated kFold accuracy scores are', cross_val_score(pipeline_nb.named_steps['classifier'], X_train_tfidf, y_train, scoring='precision', cv= rkfold, n_jobs=-1))\n",
    "\n",
    "# print('The average KFold scores is', np.mean(cross_val_score(pipeline.named_steps['classifier'], X_train_tfidf, y_train, scoring='accuracy', cv=kfold, n_jobs=-1)))\n",
    "# print('The average RepeatedKFold score is', np.mean(cross_val_score(pipeline.named_steps['classifier'], X_train_tfidf, y_train, cv=rkfold, n_jobs=-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Ask for user input\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m rating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEnter the rating (1-5): \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m comment \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter the comment: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Create a DataFrame with the user input\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Ask for user input\n",
    "rating = int(input(\"Enter the rating (1-5): \"))\n",
    "comment = input(\"Enter the comment: \")\n",
    "\n",
    "# Create a DataFrame with the user input\n",
    "user_data = pd.DataFrame({'rating': [rating],\n",
    "                          'comments': [comment]})\n",
    "\n",
    "# Transform the user input using the TF-IDF vectorizer\n",
    "user_data_tfidf = pipeline.named_steps['tfidf'].transform(user_data['comments'])\n",
    "\n",
    "# Predict the output using the trained classifier\n",
    "prediction = pipeline.named_steps['classifier'].predict(user_data_tfidf.toarray())\n",
    "\n",
    "# Calculate accuracy if actual output is available\n",
    "# OR (Original reviews, presumably human-created and authentic) = 0\n",
    "# CG (Computer-generated fake reviews) = 1\n",
    "actual_output = 0  \n",
    "accuracy = accuracy_score([actual_output], prediction)\n",
    "# Print the prediction and accuracy\n",
    "if prediction[0] == 0:\n",
    "    print(\"Original review (OR)\")\n",
    "else:\n",
    "    print(\"Computer-generated fake review (CG)\")\n",
    "\n",
    "print(\"Prediction Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "Below are backup code that didn't really work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform each comment row into tfidf array\n",
    "df['comments'] = df['comments'].astype(str)\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "# print(df['comments'])\n",
    "for index, row in df.iterrows():\n",
    "    # Transform the comment into a TF-IDF array\n",
    "    comment = row['comments']\n",
    "    # Check if the comment is empty or contains only stop words\n",
    "    \n",
    "\n",
    "    # Transform the comment into a TF-IDF array\n",
    "    comment_tfidf = vectorizer.fit_transform([comment]).toarray()\n",
    "    # Replace the original comment with its TF-IDF array\n",
    "    df.at[index, 'comments'] = comment_tfidf\n",
    "\n",
    "# response = vectorizer.fit_transform(df['comments'])\n",
    "# df['comments'] = response.getnnz()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Initialize the Naive Bayes classifier\n",
    "model = GaussianNB()\n",
    "print(\"error1\")\n",
    "# Train the classifier\n",
    "model.fit(X_train, y_train)\n",
    "print(\"error2\")\n",
    "\n",
    "# Predictions on the training set\n",
    "train_preds = model.predict(X_train)\n",
    "print(\"error3\")\n",
    "\n",
    "# Predictions on the testing set\n",
    "test_preds = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "train_accuracy = accuracy_score(y_train, train_preds)\n",
    "test_accuracy = accuracy_score(y_test, test_preds)\n",
    "\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Testing Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
